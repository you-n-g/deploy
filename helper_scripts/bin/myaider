#!/bin/sh

# Check if CHAT_MODEL is set in the environment
# if [ -z "$CHAT_MODEL" ]; then
#   echo "Error: CHAT_MODEL environment variable is not set." >&2
#   exit 1
# fi

# Check if WEAK_MODEL is set in the environment, default to CHAT_MODEL if not
# if [ -z "$WEAK_MODEL" ]; then
#   WEAK_MODEL="$CHAT_MODEL"
# fi

# aider --model "$CHAT_MODEL" --weak-model "$WEAK_MODEL" --editor-model "$CHAT_MODEL" --architect --no-show-model-warnings --editor "nvim --cmd 'let g:flatten_wait=1' --cmd 'cnoremap wq lua vim.cmd(\"w\"); require\"snacks\".bufdelete()'" --watch-files --subtree-only --no-auto-commit "$@"
# I found architect mode will make it more accurate.

# the sota model;
# --reasoning-effort high
export LITELLM_PROXY_API_KEY=sk-1234
export LITELLM_PROXY_API_BASE=http://ep14.213428.xyz:4000
# litellm_proxy will make the streaming work.

# The following is ranked by the leaderboard on https://aider.chat/docs/leaderboards/

# CHAT_MODEL=${CHAT_MODEL:-"litellm_proxy/o3_coreai"}
CHAT_MODEL=${CHAT_MODEL:-"litellm_proxy/gpt-5"}
WEAK_MODEL=${WEAK_MODEL:-${CHAT_MODEL:-"litellm_proxy/gpt-4.1"}}

echo "CHAT_MODEL: $CHAT_MODEL, WEAK_MODEL: $WEAK_MODEL"

uvx --from aider-chat aider --model "$CHAT_MODEL" --reasoning-effort high --edit-format diff --weak-model "$WEAK_MODEL" --no-show-model-warnings --editor "nvim --cmd 'let g:flatten_wait=1' --cmd 'cnoremap wq lua vim.cmd(\"w\"); require\"snacks\".bufdelete()'" --watch-files --subtree-only --no-auto-commit "$@"

# uvx --from aider-chat aider --model "litellm_proxy/o3_coreai" --weak-model "litellm_proxy/gpt-4.1" --editor-model "litellm_proxy/gpt-4.1" --architect --no-show-model-warnings --editor "nvim --cmd 'let g:flatten_wait=1' --cmd 'cnoremap wq lua vim.cmd(\"w\"); require\"snacks\".bufdelete()'" --watch-files --subtree-only --no-auto-commit "$@"
# Sometimes, it will only answer my question without do practical work....


cat << "markdown" > /dev/null
# Guidelines

# .aiderignore
markdown
